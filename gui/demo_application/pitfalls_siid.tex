\section{Pitfalls}
\note{Use this section to open discussion (no conclusion section) ?}

Data mining is an iterative process of refining hypotheses. The tool
generates hypotheses about the data, here in the form of
redescriptions. Then the user is able to select one, edit it, let the
tool expand it. When satisfied with it, the user can remove redundant
hypotheses and move on to the next one of interest. That is, at some
point he is able to state that now, the information provided by the
current hypothesis is admitted to be known, i.e. included in the
knowledge and further hypotheses that does not add any information to
that knowledge should be discarded.
However, quantifying redundancy between hypothesis is a difficult problem.

A data mining process is typically sparked by a question. But the
question typically remains implicit and the analyist only formulates
an hypothesis to answer it. Then, the mining tool can indicates
whether the data supports the hypothesis, in other words help look for
evidence supporting it. However, the fact that the hypothesis holds
does not mean that it is the best answer to the original question.  In
redescription mining, when considering an edited redescription (and
mabye also in any case), the tool should allow to evaluate the
significance and interestingness of the redescription using \pValue{}s
or randomization techniques.  Other related results, redescriptions
covering roughly the same area, containing the same variables or
having similar statistics, should be suggested to provide context to
the current redescription and challenge that hypothesis.

When interpreting a redescription, one should always bear in mind
the assumptions attached to it. For example, whether some variables
were disabled or whether the focus was put on some area when it was
generated.  Hence, keeping track of the constraints used when mining a
redescription is essential. However, if the user is allowed to stop
the extension process, modify the constraints and resume the search,
this might be fairly intricate and interpretation of the results
become impossible.

It is possible to evaluate a completely hand-crafted redescription. Is this a problem? Why?
What is the difference between generating hypotheses from the data versus backing hypotheses with the data.
How to avoid that the user finds what he is looking for and only that?
That is, a tool not to explore data and formulate new hypotheses, but to find arguments to support pre-existing theories?

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "siren_iid"
%%% End: 
