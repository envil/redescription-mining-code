\section{Discussion}
\note{Use this section to open discussion (no conclusion section) ?}

This paper presents a tool for interactive and visual redescription
mining. While we believe that the goals---and the methods we present
to achieve them---are easy to accept as reasonable, we want to point
out that there are still many open problems, both conceptual and
technical, that need to be solved. 

In the heart of interactive data mining is the user's ability to tell
the algorithm that he wants more or less certain type of results. In
principle, this is not a problem in \Siren: the user simply selects a
redescription he wants to remove from the beam search or extend
more. The problem, however, is that there can be (and usually are)
other, similar redescriptions that the user might also want to remove
or extend. He can do that manually, of course, but with larger number
of redescriptions, the process becomes unbearably tedious very soon.

A solution to this problem would be to remove (or extend) all similar
redescriptions. But how to define the similarity? To give an example,
consider a case when the user finds a redescription saying that the
area where the Polar Bear lives is the area with January's mean
temperature below $-20$ degrees Celsius, in other words, Polar Bear
lives in cold. This is hardly a surprising result, and the user might
want to remove it (and other similar results) from the search. But we
can characterize the cold areas using other variables than just
January's mean temperature, so it is not enough to just stop extending
any redescription with Polar Bear and January's mean temperature in
it. Also, we cannot just remove all the redescriptions with Polar
Bear---that could remove some very interesting redescriptions,
too. Finally, we could consider the area in which the redescription
holds. But even that leaves a lot to be hoped for: if we remove all
redescriptions that contain that area, we probably remove too many
redescriptions, but if we instead remove redescriptions
 contained in the area, we probably miss most of the
redescriptions we should remove.  

The problem of removing and extending similar redescriptions is
closely related to that of redundancy reduction. There are often
multiple redescriptions that represent the same phenomenon (think of
the Polar Bears living in the cold areas), and ideally, we would like
to present only one of them to the user. In other words, we do not want
to present to the user any redescriptions that do not add any (or add
only marginally) new information over the redescriptions he has
already seen. But as with deciding which redescription is similar to a
selected one, also quantifying the redundancy between redescriptions
is a difficult problem.

% Data mining is an iterative process of refining hypotheses. The tool
% generates hypotheses about the data, here in the form of
% redescriptions. Then the user is able to select one, edit it, let the
% tool expand it. When satisfied with it, the user can remove redundant
% hypotheses and move on to the next one of interest. That is, at some
% point he is able to state that now, the information provided by the
% current hypothesis is admitted to be known, i.e. included in the
% knowledge and further hypotheses that does not add any information to
% that knowledge should be discarded.
% However, quantifying redundancy between hypothesis is a difficult problem.

% A data mining process is typically sparked by a question. But the
% question typically remains implicit and the analyst only formulates
% an hypothesis to answer it. Then, the mining tool can indicates
% whether the data supports the hypothesis, in other words help look for
% evidence supporting it. However, the fact that the hypothesis holds
% does not mean that it is the best answer to the original question.  In
% redescription mining, when considering an edited redescription (and
% maybe also in any case), the tool should allow to evaluate the
% significance and interestingness of the redescription using \pValue{}s
% or randomization techniques.  Other related results, redescriptions
% covering roughly the same area, containing the same variables or
% having similar statistics, should be suggested to provide context to
% the current redescription and challenge that hypothesis.

When interpreting a redescription, one should always bear in mind
the assumptions attached to it. For example, whether some variables
were disabled or whether the focus was put on some area when it was
generated.  Hence, keeping track of the constraints used when mining a
redescription is essential. However, if the user is allowed to stop
the extension process, modify the constraints and resume the search,
this might be fairly intricate and interpretation of the results
become impossible.

The goal of data mining is to find new and interesting information
from the data. In interactive data mining in general, and with the
tools discussed in this paper in particular, the user can guide the
data mining method towards the results he prefers. This raises new
problems. First, we have to control that the data supports the results
the user finds and second, we must be careful that the user actually
finds new information, not just the information he already knew. 

The first problem, making sure that the obtained results are supported
by the data, is ages old in sciences. In short, it is the question of
testing the significance of a hypothesis, and there is a vast body of
statistical literature about it. Our proposed algorithms mitigate the
problem by computing a $p$-value, but as it is based on a fixed null
hypothesis, it is not adequate in every case.

The second problem is more conceptual: taken to an extreme, the
interactivity removes the data mining from the interactive data
mining. If the user more or less directly tells the algorithm the
redescription he wants to see, the \Siren\ program turns into a mere
plotting interface. Even on the less extreme case, the user can easily
(an unwittingly) guide the algorithm towards the kind of results he
wanted to see. Together with the fact that we can only check against a
fixed null hypothesis, this causes a considerable risk of false
findings. The onus is on the user to make sure he does not misuse the algorithm.

% It is possible to evaluate a completely hand-crafted redescription. Is this a problem? Why?
% What is the difference between generating hypotheses from the data versus backing hypotheses with the data.
% How to avoid that the user finds what he is looking for and only that?
% That is, a tool not to explore data and formulate new hypotheses, but to find arguments to support pre-existing theories?

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "siren_iid"
%%% End: 
